{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ce5311c3",
   "metadata": {},
   "source": [
    "This code is not written by me its all Chat GPT as i am still learning to do this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87715569-4957-4b57-9325-fc4151698a62",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Solution Generation\n",
    "\n",
    "import openai\n",
    "\n",
    "client = openai.OpenAI(api_key=\"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\")\n",
    "\n",
    "def solve_ai_ml_question(question):\n",
    "    prompt = f\"\"\"\n",
    "    Solve the following AI/ML question in a detailed, step-by-step manner. Clearly explain each step in the reasoning or calculation process. The explanation should be logically structured so it can be used later for classification based on difficulty and topic.\n",
    "\n",
    "    Question:\n",
    "    \\\"\\\"\\\"\n",
    "    {question}\n",
    "    \\\"\\\"\\\"\n",
    "\n",
    "    Provide your answer in the following format:\n",
    "\n",
    "    Answer:\n",
    "    1. **Understanding the question**: [Brief description of what the question is asking]\n",
    "    2. **Key Concepts Used**: [List the key AI/ML concepts required]\n",
    "    3. **Step-by-step Solution**:\n",
    "       - Step 1: ...\n",
    "       - Step 2: ...\n",
    "       - ...\n",
    "    4. **Final Answer**: [Conclusive answer]\n",
    "    5. **Difficulty Level (Self-estimated)**: [Easy/Medium/Hard]\n",
    "    6. **Related Topic(s)**: [E.g., supervised learning, classification, decision trees]\n",
    "    \"\"\"\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "        temperature=0.7\n",
    "    )\n",
    "\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "question = \"What is the difference between supervised and unsupervised learning?\"\n",
    "structured_solution = solve_ai_ml_question(question)\n",
    "print(structured_solution)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4960ae7-3081-45bb-91dc-760d3aa8a7ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "\n",
    "# Sample dataset\n",
    "data = pd.DataFrame({\n",
    "    'question': [\n",
    "        \"What is overfitting in machine learning?\",\n",
    "        \"Calculate the accuracy of a model given predictions.\",\n",
    "        \"Explain the concept of gradient descent.\"\n",
    "    ],\n",
    "    'steps_required': [2, 4, 3],\n",
    "    'question_type': ['Conceptual', 'Calculative', 'Conceptual'],\n",
    "})\n",
    "# Word count as a feature\n",
    "data['word_count'] = data['question'].apply(lambda x: len(x.split()))\n",
    "# 1. TF-IDF vectorization\n",
    "vectorizer = TfidfVectorizer(stop_words='english', max_features=100)\n",
    "tfidf_matrix = vectorizer.fit_transform(data['question'])\n",
    "# 2. Encode question_type (Conceptual/Calculative)\n",
    "ohe = OneHotEncoder(sparse_output=False)\n",
    "question_type_encoded = ohe.fit_transform(data[['question_type']])\n",
    "# 3. Combine numerical features\n",
    "numeric_features = data[['steps_required', 'word_count']].values\n",
    "# 4. Standardize numeric features\n",
    "scaler = StandardScaler()\n",
    "scaled_numeric = scaler.fit_transform(numeric_features)\n",
    "# 5. Concatenate all features\n",
    "from scipy.sparse import hstack\n",
    "# Make sure all are sparse or dense, so we convert numeric to sparse\n",
    "final_matrix = hstack([tfidf_matrix, scaled_numeric, question_type_encoded])\n",
    "print(f\"Final feature matrix: {final_matrix}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19654953-b4d5-4b81-9eb9-8f0455ceea60",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# Choose number of clusters â€” assume 3: easy, medium, hard\n",
    "kmeans = KMeans(n_clusters=3, random_state=42)\n",
    "\n",
    "# Fit the model on the sparse final feature matrix\n",
    "clusters = kmeans.fit_predict(final_matrix)\n",
    "\n",
    "# Add the cluster labels to the original data\n",
    "data['difficulty_cluster'] = clusters\n",
    "\n",
    "# Display with clusters\n",
    "print(data[['question', 'difficulty_cluster']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eda24e0d-7826-4df4-9b0d-acefa29671a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add relevant features to analyze\n",
    "data['steps_required'] = data['steps_required']\n",
    "data['word_count'] = data['word_count']\n",
    "data['question_type'] = data['question_type']\n",
    "\n",
    "# Group by cluster to summarize\n",
    "cluster_summary = data.groupby('difficulty_cluster')[['steps_required', 'word_count']].mean()\n",
    "cluster_summary['question_type_mode'] = data.groupby('difficulty_cluster')['question_type'].agg(lambda x: x.mode()[0])\n",
    "\n",
    "print(cluster_summary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11fab97d-b07b-454b-923b-8ce902b114ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "# Initialize the client (you can set OPENAI_API_KEY in your environment instead)\n",
    "client = OpenAI(api_key=\"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\")  # Replace with your actual key or use env var\n",
    "\n",
    "# Difficulty mapping\n",
    "DIFFICULTY_LEVELS = ['easy', 'medium', 'hard']\n",
    "\n",
    "def increase_difficulty(question, current_label):\n",
    "    \"\"\"\n",
    "    Increases difficulty of the question by one level. \n",
    "    If already 'hard', it rephrases the question without changing the difficulty.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        current_index = DIFFICULTY_LEVELS.index(current_label.lower())\n",
    "    except ValueError:\n",
    "        raise ValueError(f\"Unknown difficulty label: {current_label}\")\n",
    "\n",
    "    if current_index < 2:  # If not 'hard'\n",
    "        target_label = DIFFICULTY_LEVELS[current_index + 1]\n",
    "        prompt = (\n",
    "            f\"Increase the difficulty of the following {current_label} AI/ML question \"\n",
    "            f\"to {target_label} by making it more challenging or technical.\\n\\n\"\n",
    "            f\"Question: \\\"{question}\\\"\\n\\n\"\n",
    "            f\"Return the updated question only.\"\n",
    "        )\n",
    "    else:\n",
    "        target_label = current_label\n",
    "        prompt = (\n",
    "            f\"Rephrase the following hard AI/ML question without changing its difficulty level.\\n\\n\"\n",
    "            f\"Question: \\\"{question}\\\"\\n\\n\"\n",
    "            f\"Make it sound slightly different but keep the same challenge level.\"\n",
    "        )\n",
    "\n",
    "    # OpenAI API call\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo\",  # or \"gpt-4\" if you have access\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are an AI/ML question rewriting assistant.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ],\n",
    "        temperature=0.7,\n",
    "        max_tokens=150\n",
    "    )\n",
    "\n",
    "    new_question = response.choices[0].message.content.strip()\n",
    "    return new_question, target_label\n",
    "\n",
    "\n",
    "original_q = \"What is overfitting in machine learning?\"\n",
    "original_label = \"Easy\"\n",
    "\n",
    "new_q, new_label = increase_difficulty(original_q, original_label)\n",
    "\n",
    "print(f\"Original: {original_q} ({original_label})\")\n",
    "print(f\"Modified: {new_q} ({new_label})\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
